#!/bin/bash
# Copyright 2016 The Kubernetes Authors All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o nounset
set -o pipefail


NODEUP_URL=https://kubeupv2.s3.amazonaws.com/kops/1.9.0/linux/amd64/nodeup
NODEUP_HASH=54ecae66a2b4e1409b36fc00b550f2501afedbfc


function ensure-install-dir() {
  INSTALL_DIR="/var/cache/kubernetes-install"
  # On ContainerOS, we install to /var/lib/toolbox install (because of noexec)
  if [[ -d /var/lib/toolbox ]]; then
    INSTALL_DIR="/var/lib/toolbox/kubernetes-install"
  fi
  mkdir -p ${INSTALL_DIR}
  cd ${INSTALL_DIR}
}

# Retry a download until we get it. Takes a hash and a set of URLs.
#
# $1 is the sha1 of the URL. Can be "" if the sha1 is unknown.
# $2+ are the URLs to download.
download-or-bust() {
  local -r hash="$1"
  shift 1

  urls=( $* )
  while true; do
    for url in "${urls[@]}"; do
      local file="${url##*/}"
      rm -f "${file}"

      if [[ $(which curl) ]]; then
        if ! curl -f --ipv4 -Lo "${file}" --connect-timeout 20 --retry 6 --retry-delay 10 "${url}"; then
          echo "== Failed to curl ${url}. Retrying. =="
          break
        fi
      elif [[ $(which wget ) ]]; then
        if ! wget --inet4-only -O "${file}" --connect-timeout=20 --tries=6 --wait=10 "${url}"; then
          echo "== Failed to wget ${url}. Retrying. =="
          break
        fi
      else
        echo "== Could not find curl or wget. Retrying. =="
        break
      fi

      if [[ -n "${hash}" ]] && ! validate-hash "${file}" "${hash}"; then
        echo "== Hash validation of ${url} failed. Retrying. =="
      else
        if [[ -n "${hash}" ]]; then
          echo "== Downloaded ${url} (SHA1 = ${hash}) =="
        else
          echo "== Downloaded ${url} =="
        fi
        return
      fi
    done

    echo "All downloads failed; sleeping before retrying"
    sleep 60
  done
}

validate-hash() {
  local -r file="$1"
  local -r expected="$2"
  local actual

  actual=$(sha1sum ${file} | awk '{ print $1 }') || true
  if [[ "${actual}" != "${expected}" ]]; then
    echo "== ${file} corrupted, sha1 ${actual} doesn't match expected ${expected} =="
    return 1
  fi
}

function split-commas() {
  echo $1 | tr "," "\n"
}

function try-download-release() {
  # TODO(zmerlynn): Now we REALLY have no excuse not to do the reboot
  # optimization.

  local -r nodeup_urls=( $(split-commas "${NODEUP_URL}") )
  local -r nodeup_filename="${nodeup_urls[0]##*/}"
  if [[ -n "${NODEUP_HASH:-}" ]]; then
    local -r nodeup_hash="${NODEUP_HASH}"
  else
  # TODO: Remove?
    echo "Downloading sha1 (not found in env)"
    download-or-bust "" "${nodeup_urls[@]/%/.sha1}"
    local -r nodeup_hash=$(cat "${nodeup_filename}.sha1")
  fi

  echo "Downloading nodeup (${nodeup_urls[@]})"
  download-or-bust "${nodeup_hash}" "${nodeup_urls[@]}"

  chmod +x nodeup
}

function download-release() {
  # In case of failure checking integrity of release, retry.
  until try-download-release; do
    sleep 15
    echo "Couldn't download release. Retrying..."
  done

  echo "Running nodeup"
  # We can't run in the foreground because of https://github.com/docker/docker/issues/23793
  ( cd ${INSTALL_DIR}; ./nodeup --install-systemd-unit --conf=${INSTALL_DIR}/kube_env.yaml --v=8  )
}

####################################################################################

/bin/systemd-machine-id-setup || echo "failed to set up ensure machine-id configured"

echo "== nodeup node config starting =="
ensure-install-dir

cat > cluster_spec.yaml << '__EOF_CLUSTER_SPEC'
cloudConfig: null
docker:
  bridge: ""
  ipMasq: false
  ipTables: false
  logDriver: json-file
  logLevel: warn
  logOpt:
  - max-size=10m
  - max-file=5
  storage: overlay,aufs
  version: 1.13.1
encryptionConfig: null
etcdClusters:
  events:
    image: gcr.io/google_containers/etcd:2.2.1
    version: 2.2.1
  main:
    image: gcr.io/google_containers/etcd:2.2.1
    version: 2.2.1
kubeAPIServer:
  address: 127.0.0.1
  admissionControl:
  - Initializers
  - NamespaceLifecycle
  - LimitRanger
  - ServiceAccount
  - PersistentVolumeLabel
  - DefaultStorageClass
  - DefaultTolerationSeconds
  - NodeRestriction
  - ResourceQuota
  allowPrivileged: true
  anonymousAuth: false
  apiServerCount: 1
  authorizationMode: AlwaysAllow
  cloudProvider: aws
  etcdServers:
  - http://127.0.0.1:4001
  etcdServersOverrides:
  - /events#http://127.0.0.1:4002
  image: gcr.io/google_containers/kube-apiserver:v1.8.7
  insecurePort: 8080
  kubeletPreferredAddressTypes:
  - InternalIP
  - Hostname
  - ExternalIP
  logLevel: 2
  requestheaderAllowedNames:
  - aggregator
  requestheaderExtraHeaderPrefixes:
  - X-Remote-Extra-
  requestheaderGroupHeaders:
  - X-Remote-Group
  requestheaderUsernameHeaders:
  - X-Remote-User
  securePort: 443
  serviceClusterIPRange: 100.64.0.0/13
  storageBackend: etcd2
kubeControllerManager:
  allocateNodeCIDRs: true
  attachDetachReconcileSyncPeriod: 1m0s
  cloudProvider: aws
  clusterCIDR: 100.96.0.0/11
  clusterName: #cluster_name#
  configureCloudRoutes: true
  image: gcr.io/google_containers/kube-controller-manager:v1.8.7
  leaderElection:
    leaderElect: true
  logLevel: 2
  useServiceAccountCredentials: true
kubeProxy:
  clusterCIDR: 100.96.0.0/11
  cpuRequest: 100m
  hostnameOverride: '@aws'
  image: gcr.io/google_containers/kube-proxy:v1.8.7
  logLevel: 2
kubeScheduler:
  image: gcr.io/google_containers/kube-scheduler:v1.8.7
  leaderElection:
    leaderElect: true
  logLevel: 2
kubelet:
  allowPrivileged: true
  cgroupRoot: /
  cloudProvider: aws
  clusterDNS: 100.64.0.10
  clusterDomain: cluster.local
  enableDebuggingHandlers: true
  evictionHard: memory.available<100Mi,nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<10%,imagefs.inodesFree<5%
  featureGates:
    ExperimentalCriticalPodAnnotation: "true"
  hostnameOverride: '@aws'
  kubeconfigPath: /var/lib/kubelet/kubeconfig
  logLevel: 2
  networkPluginMTU: 9001
  networkPluginName: kubenet
  nonMasqueradeCIDR: 100.64.0.0/10
  podInfraContainerImage: gcr.io/google_containers/pause-amd64:3.0
  podManifestPath: /etc/kubernetes/manifests
  requireKubeconfig: true
masterKubelet:
  allowPrivileged: true
  cgroupRoot: /
  cloudProvider: aws
  clusterDNS: 100.64.0.10
  clusterDomain: cluster.local
  enableDebuggingHandlers: true
  evictionHard: memory.available<100Mi,nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<10%,imagefs.inodesFree<5%
  featureGates:
    ExperimentalCriticalPodAnnotation: "true"
  hostnameOverride: '@aws'
  kubeconfigPath: /var/lib/kubelet/kubeconfig
  logLevel: 2
  networkPluginMTU: 9001
  networkPluginName: kubenet
  nonMasqueradeCIDR: 100.64.0.0/10
  podInfraContainerImage: gcr.io/google_containers/pause-amd64:3.0
  podManifestPath: /etc/kubernetes/manifests
  registerSchedulable: false
  requireKubeconfig: true

__EOF_CLUSTER_SPEC

cat > ig_spec.yaml << '__EOF_IG_SPEC'
kubelet: null
nodeLabels:
  kops.k8s.io/instancegroup: master-us-east-2a
suspendProcesses: null
taints: null

__EOF_IG_SPEC

cat > kube_env.yaml << '__EOF_KUBE_ENV'
Assets:
- 0f3a59e4c0aae8c2b2a0924d8ace010ebf39f48e@https://storage.googleapis.com/kubernetes-release/release/v1.8.7/bin/linux/amd64/kubelet
- 36340bb4bb158357fe36ffd545d8295774f55ed9@https://storage.googleapis.com/kubernetes-release/release/v1.8.7/bin/linux/amd64/kubectl
- 1d9788b0f5420e1a219aad2cb8681823fc515e7c@https://storage.googleapis.com/kubernetes-release/network-plugins/cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff.tar.gz
- c6f310214f687b6c2f32e81c2a49235182950be3@https://kubeupv2.s3.amazonaws.com/kops/1.9.0/linux/amd64/utils.tar.gz
ClusterName: #cluster_name#
ConfigBase: s3://k8s-state-#cluster_name_hyphenated#/#cluster_name#
InstanceGroupName: master-us-east-2a
Tags:
- _automatic_upgrades
- _aws
- _kubernetes_master
channels:
- s3://k8s-state-#cluster_name_hyphenated#/#cluster_name#/addons/bootstrap-channel.yaml
protokubeImage:
  hash: 4bbfcc6df1c1c0953bd0532113a74b7ae21e0ded
  name: protokube:1.9.0
  source: https://kubeupv2.s3.amazonaws.com/kops/1.9.0/images/protokube.tar.gz

__EOF_KUBE_ENV

download-release
echo "== nodeup node config done =="

## Initial bootstrap commands telnet, jq, stern
apt-get update
apt-get install telnet
apt-get install jq
wget https://github.com/wercker/stern/releases/download/1.5.1/stern_linux_amd64
mv stern_linux_amd64 /opt/stern
ln -s /opt/stern /usr/bin/stern
chmod +x /usr/bin/stern
##kubectl install
curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl && \
chmod +x ./kubectl && \
sudo mv ./kubectl /usr/bin/kubectl
#----helm start------#
## Install helm
wget https://storage.googleapis.com/kubernetes-helm/helm-v2.8.1-linux-amd64.tar.gz
tar -xvf helm-v2.8.1-linux-amd64.tar.gz
cd linux-amd64
mv helm /usr/bin
## Wait for api server to be accessibe and then do helm init
echo "Waiting for port 8080..."
while ! nc -z localhost 8080; do   
  sleep 0.1 # wait for 1/10 of the second before check again
done
echo "Api server accessible"
echo "Waiting for kube-system"
while ! kubectl get namespace | grep kube-system | grep Active; do   
  sleep 0.1 # wait for 1/10 of the second before check again
done
echo "Kube system alive"
helm init

#----alias start------#
echo '
alias ke="kubectl edit $@"
alias kg="kubectl get $@"
alias kgcm="kubectl get cm $@"
alias kgss="kubectl get statefulsets $@"
alias kgpvc="kubectl get pvc $@"
alias kgpv="kubectl get pv $@"
alias kge="kubectl get events --tail 300 $@"
alias kdrc="kubectl delete rc $@"
alias kgi="kubectl get ingress $@"
alias krs="kubectl rollout status $@"
alias kgss="kubectl get statefulsets $@"
alias kds="kubectl delete service $@"
alias kdj="kubectl delete job $@"
alias ka="kubectl apply -f $@"
alias kdi="kubectl describe ing"
alias kgj="kubectl get jobs"
alias kgc="kubectl get cronjobs"
alias kgs="kubectl get svc"
alias kgd="kubectl get deployments $@"
alias kr="kubectl run -it --image $@"
alias kdd="kubectl delete deployments $@"
alias kdp="kubectl delete po $@"
alias kdcm="kubectl delete cm $@"
alias kdepvc="kubectl delete pvc $@"
alias kdpv="kubectl describe pv $@"
alias kdpv="kubectl delete pv $@"
alias kdpf="kubectl delete po --force --grace-period=0 $@"
alias kdpo="kubectl describe po $@"
alias kgpo="kubectl get po  --sort-by=.status.startTime  $@"
alias kpow="kubectl get po -w  $@"
alias keb="kubectl exec -it $@"
alias kl="kubectl logs $@"
alias klf="kubectl logs --tail 100 $@"
alias kd="kubectl describe $@"
alias drb="docker run -it $@"
alias drmi="docker rmi $@"
alias kall="kubectl get svc,deployments,pods,cronjob,jobs,rs,configmap,pdb,statefulset,daemonset,pvc,sc"
alias kdpo="kubectl describe po $@"
alias kdc="kubectl describe cronjobs $@"' > ~/.bashrc
#----alias end---------#

kubectl rollout status  deployment/tiller-deploy -n kube-system
kubectl create serviceaccount --namespace kube-system tiller
kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
kubectl patch deploy --namespace kube-system tiller-deploy -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}' 
#------helm end----#
## Generate tls secret for kube registry self signed
openssl req -newkey rsa:4096 -nodes -sha256 -keyout domain.key -x509 -days 3650 -out domain.crt -subj "/C=US/ST=NY/L=NYC/O=SlingMedia/OU=Backend/CN=#docker_registry_host#"
## Get domain.crt
## Get domain.key
echo "Waiting for aws command"
while ! which /usr/local/bin/aws; do   
  sleep 0.1 # wait for 1/10 of the second before check again
done
echo "aws command available"

/usr/local/bin/aws s3 cp s3://k8s-state-#cluster_name_hyphenated#/#cluster_name#/docker-state/domain.crt domain.crt
/usr/local/bin/aws s3 cp s3://k8s-state-#cluster_name_hyphenated#/#cluster_name#/docker-state/domain.key domain.key

kubectl create secret generic registry-tls-secret --from-file=domain.crt=domain.crt --from-file=domain.key=domain.key
cp domain.crt ca.crt
## Create registry

### Following is done only on master using this script use ansible or other tools to copy this to other nodes
### This assumes that the directory at which openssl is running is same as what is used to run below commands
echo "Copying certificates to master ONLY !! Copying to others has to be done some other way"
mkdir -p /etc/docker/certs.d/#docker_registry_host#:5000
cp -rf ca.crt /etc/docker/certs.d/#docker_registry_host#:5000



### Create kubernetes pod for docker registry
## Apply the configuration
echo '# --------------------- Storage class for aws ------------- #
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: slow
  namespace: default
provisioner: kubernetes.io/aws-ebs
reclaimPolicy: Retain
parameters:
  type: gp2
  zone: us-east-2a
---
# --------------------- Persistent Volume claim for 20Gi for registry ------------- #
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: image-claim
  namespace: default
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 60Gi
  storageClassName: slow
---
# --------------------- Kube Registry Deployment ------------- #
apiVersion: apps/v1beta2 # for versions before 1.8.0 use apps/v1beta1
kind: Deployment
metadata:
  name: kube-registry-v0
  namespace: default
  labels:
    k8s-app: kube-registry
    version: v0
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: kube-registry
  template:
    metadata:
      labels:
        k8s-app: kube-registry
        version: v0
    spec:
      containers:
        - name: registry
          image: registry:2
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          env:
          - name: REGISTRY_HTTP_ADDR
            value: :5000
          - name: REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY
            value: /var/lib/registry
          - name: REGISTRY_HTTP_TLS_CERTIFICATE
            value: /certs/domain.crt
          - name: REGISTRY_HTTP_TLS_KEY
            value: /certs/domain.key
          volumeMounts:
          - name: image-store
            mountPath: /var/lib/registry
          - name: cert-dir
            mountPath: /certs
          ports:
          - containerPort: 5000
            name: registry
            protocol: TCP
      volumes:
      - name: image-store
        persistentVolumeClaim:
          claimName: image-claim
      - name: cert-dir
        secret:
          secretName: registry-tls-secret
---
# --------------------- Kube Registry service ------------- #
apiVersion: v1
kind: Service
metadata:
  name: kube-registry
  namespace: default
  labels:
    k8s-app: kube-registry
#    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "KubeRegistry"
spec:
  selector:
    k8s-app: kube-registry
  clusterIP: 100.69.212.32
  type: NodePort
  ports:
  - name: registry
    port: 5000
    protocol: TCP' > /tmp/external-tools.yml
kubectl apply -f /tmp/external-tools.yml
### END Enable Kube registry service ###

### Wait until regisy is available
kubectl rollout status deployments/kube-registry-v0


